LangChain多阶段侦探小说生成工作流设计
为实现逐步创作一部约5000字、风格类似福尔摩斯/波洛的侦探短篇小说（主人公为11岁男孩“蛋蛋”），可以将写作流程拆解为多个阶段，利用LangChain的链条和Agent机制在每阶段生成和控制内容。下面按阶段阐述工作流的设计，每阶段包括目标、输入输出、提示词方案、使用的LangChain模块、记忆管理以及阶段结束的校验方式。
阶段一：立项（小说概念设定）
•	阶段目标：确定小说的总体构思和设定，包括案件背景、主要角色（如侦探“蛋蛋”、受害者、嫌疑人等）和故事基调。风格定位为经典推理（类似福尔摩斯或波洛），突出逻辑推理和悬念。
•	输入：用户提供的创作指令或基本要求（例如主角身份、字数、风格等）。本例中，已知主角是11岁男孩“蛋蛋”，风格类似福尔摩斯推理故事。
•	输出：小说的概要构想，包含案件简介、主要角色介绍、故事发生的时代/地点，以及整体悬疑氛围描述。输出形式可为一段叙述或要点列表，描述“故事的核心悬念是什么、谁是凶手（不公开给读者）、侦探将面临怎样的谜题”等。
•	提示词设计：使用LLMChain构造提示，让模型扮演“悬疑策划人”。如系统提示可说明：“你是一位推理小说策划编辑，请根据以下要求提供一个短篇侦探故事的构思，包括案件背景、主角和其他关键角色设定、故事风格。” 用户提示则提供已知要素（主人公蛋蛋11岁、字数约5000、风格类似福尔摩斯等）。模型需产出完整的故事设定方案。
•	实现方式：采用LangChain的LLMChain执行单轮问答。提示模板注入上述要求，并要求输出结构化的故事概要（例如分段描述背景、人物、案件）。不需要Agent工具调用，只需语言模型完成创意生成。此阶段可以使用LangChain的ChatPromptTemplate定义复杂提示词，也可以指定输出格式（例如markdown列表）。
•	记忆管理：本阶段不涉及长上下文，无需特殊记忆模块。只是首次调用LLM获取创意草案。
•	阶段校验：校对模型输出的故事概念是否符合要求：是否包含主要元素（案件、主角蛋蛋、推理风格）且风格基调合理。如果模型输出不完整或偏离主题，可在人审基础上重新调整提示词再生成。此阶段输出将作为后续阶段的基础，因此需要确保概念清晰、有吸引力。可考虑简单一致性检查，如确保主角年龄/身份正确，故事风格确实偏向经典推理。必要时，可用另一轮LLMChain让模型自检提纲是否满足要求并简要优化。
阶段二：诡计设计（核心谜题与真相构思）
•	阶段目标：设计小说中的核心谜题“诡计”。也就是详细规划案件真相，包括凶手是谁、作案手法、作案动机、时间线、不在场证明等推理要素，以及故事中将出现的线索与误导（红鲱鱼）。这一阶段相当于推理小说的幕后真相剧本，为后续创作提供严密的逻辑支撑。
•	输入：阶段一输出的故事概念（案件背景、角色设定等），作为上下文供模型参考。
•	输出：案件详细方案，包含：犯罪真相描述（谁是凶手、作案动机和手法）、案件时间线关键节点（比如犯案时间、发现尸体时间等）、涉及的主要线索清单（每条线索的形式、指向、表面意义和真实含义）、可能的误导情节。可以采用结构化输出，如列出“真相概述：...”“主要线索：...”“时间线：...”。
•	提示词设计：采用新的LLMChain，提示模型扮演“推理顾问”角色。提示模板例如：“基于以下故事背景，请设计该推理案件的详细真相和诡计。包括：1) 真凶身份及动机；2) 作案手法细节（如何实施犯罪且瞒天过海）；3) 时间线和不在场证明安排；4) 故事中计划出现的线索（每条线索如何体现表象与真实指向）；5) 读者可能被误导的要素。要求逻辑自洽、巧妙有新意。” 这样模型会产出完整的诡计设计方案。
•	实现方式：使用LLMChain或一个Action Agent均可。如果需要结构化结果，可以使用LangChain的输出解析器（如StructuredOutputParser）确保模型按预定格式列出真相和线索。可选扩展：在模型给出诡计设计后，利用LangChain的图数据库接口将案件要素存入知识图谱（如Neo4j）。例如，将角色、案件事件和线索作为节点，关系包括“嫌疑人-关系-受害者”、“线索-指向-嫌疑人”等。在图数据库中结构化存储故事元素，有助于后续检索和一致性检查[1]。知识图可以系统性跟踪故事元素，减少模型胡编乱造并加强叙事一致性[1]。
•	记忆管理：此阶段输入输出信息量增加，但仍在单次生成内，不需要长时记忆模块。不过可以缓存阶段二结果（真相脚本），供后续阶段频繁查阅。这可通过LangChain内存（如ConversationBufferMemory暂存）或直接将结果写入向量数据库备用。比如，将每条线索说明向量化存储，以便后续章节生成时快速检索相关线索描述用于上下文。
•	阶段校验：验证诡计设计的逻辑合理性与完整性。可在输出后引入一个检查：利用另一LLMChain读取该方案，自然语言提问例如“请检查上述案件设计中有无明显逻辑漏洞或不合理之处，并列出。” 模型若指出问题，则修改方案或提示词细化要求重新生成。人工校验也很重要，可由开发者审阅确认：是否每个线索都有作用？手法是否符合常理？一旦确认方案周全，将这些细节固化，用于后续章节内容创作时保持逻辑前后一致。必要时，将真相和线索以知识图谱形式可视化（借助Neo4j浏览）来人工检验因果关系的完整性。
阶段三：结构节拍（情节结构大纲）
•	阶段目标：规划小说的情节结构和章节划分，确保故事节奏流畅且推理元素合理铺陈。根据侦探故事典型节奏，将剧情分为引子、案件发生、调查展开（多章节线索逐步呈现）、高潮揭示真相、结局收尾等部分。每个章节的大致内容和在整体中的作用需要明确。
•	输入：阶段一的故事概念、阶段二设计的案件真相和线索清单。模型需要综合这些信息来设计情节进程。
•	输出：章节级的故事大纲（可按章或场景列出）。例如：
•	第1章：引子（介绍主人公蛋蛋，展示日常及案件发生）
•	第2章：案件现场与初步线索（警方与蛋蛋介入调查）
•	第3章：深入调查（搜集几个关键线索，每个线索对应嫌疑人动机）
•	...
•	最终章：真相大白（蛋蛋揭露诡计，解释线索并收尾）。
每章概要中应注明该章节的主要事件、所揭示的线索或疑点，以及情节张力走向。
•	提示词设计：通过LLMChain生成章节计划。提示模板如：“基于以下案件设定和真相，规划这个侦探短篇的情节结构。请列出章节划分，每章简要描述主要情节和涵盖的线索。注意保持悬念节奏递进，最终章节揭示真相并解释所有谜题。” 模型将按要求输出章节列表，可能带编号和描述。为确保风格统一，可在提示中强调：“故事风格古典推理，节奏紧凑。”
•	实现方式：使用LangChain的LLMChain，可结合ChatPromptTemplate定义多轮提示（例如System说明写作要求、User请求章节列表）。为了确保输出易于后续处理，可让模型以Markdown列表格式给出章节概览。这个阶段也可用LangChain的SequentialChain，先将阶段二结果与提示模板拼接，再将其传给LLMChain。生成的大纲结构可存储为Python的数据结构（如列表/字典），方便程序引用。
•	记忆管理：生成大纲本身不需要跨调用记忆，但需将阶段二的重要信息融入上下文。可在提示中直接插入案件真相摘要和线索列表，使模型在规划情节时能覆盖所有关键线索。因为大纲相对简短，也可将阶段二输出全部拼入提示。如果信息超长，可以先用LLM对真相和线索列表做摘要提取，再用于提示。没有必要引入长程记忆或向量检索，因为大纲生成是一步到位的过程。
•	阶段校验：拿到章节大纲后，需要检查：(a) 是否涵盖所有线索（每条关键线索应在某章出现），(b) 情节顺序是否合乎逻辑（比如调查逐步深入，高潮在接近尾声），(c) 篇幅配置是否合理（章节数适中、每章描述的事件能撑起相应字数）。这一步可半自动进行：将章节列表和之前的线索列表交给LLMChain询问：“上述大纲是否包含了所有线索？哪些线索未提及？” 如果模型列出遗漏，则需要修改大纲。人也应审阅情节是否有悬念设置和解谜递进。一旦确认大纲OK，就进入下一阶段。此时也可以将章节大纲存入向量库（如FAISS），每章说明向量化保存，以便后文生成时按需检索章节内容或顺序[2]。动态检索之前规划的内容，有助于长篇故事保持上下文一致[2]。
阶段四：线索布置（线索细节与埋设）
•	阶段目标：在既定的大纲下，进一步细化每章情节中的线索和伏笔安排。确定每一章具体呈现哪些线索、证据或误导信息，以及这些线索如何在文中出现（对白、场景、物证等）。这个阶段确保线索分布合理：既不能过于集中，也不能遗漏，且读者既能在文中察觉线索又不至于立即看穿。
•	输入：阶段二输出的线索清单/真相细节、阶段三输出的章节大纲。两者结合用于线索布置。
•	输出：详细的线索布局方案，可以按章节列出：每章将引入/提及哪些线索，怎样的形式呈现。例如：“第2章：出现线索A（在现场发现的物品）、线索B（嫌疑人证词矛盾点）”；“第3章：出现线索C ……”。每条线索还可标注其表面意义和真实指向，确保写作时准确埋下伏笔。最终形成一个章节->线索的映射表。
•	提示词设计：LLMChain继续发挥作用。可以设计提示如：“下面是故事章节大纲和案件线索列表，请为每一章指定将呈现的线索或伏笔。确保所有线索都体现在某章节，并注明线索在该章中如何出现（通过什么情节或细节）。注意线索出现的顺序和方式应服务于悬疑效果，重要线索靠近结尾揭示。” 这样模型会输出按章节标注线索的规划。
•	实现方式：可以直接使用LLMChain让模型输出章节-线索对照表。为了精准控制，也可考虑使用LangChain的Mapper类工具，或者将此作为一个小Agent任务：让Agent读取线索列表和大纲，然后依次针对每章“思考”应放哪些线索。简单方法是直接提示+LLM完成即可。可选地，在此阶段更新之前构建的知识图谱：将每条线索与对应章节建立关系 (例如在Neo4j中添加关系(Chapter)-[CONTAINS_CLUE]->(Clue))。这样图数据库全面记录了章节、角色、线索间关联，为后续检查和内容生成提供支持。
•	记忆管理：仍然是一次性输出，不涉及长记忆。但由于内容开始复杂，需确保模型提示包含充足上下文信息。可在提示中插入“章节大纲+线索列表”，或者在对话模式下先提供大纲，再提供线索列表，然后要求模型整合输出。LangChain可以用ConversationBufferWindowMemory确保这些信息都送入模型上下文。如果模型上下文长度有限，也可以先让模型逐章处理：比如一个循环中，每次提示模型：“第X章剧情是...，可用线索有哪些...?” 然后汇总。但效率而言，一次性输出更清晰。向量库在此阶段可以暂存“章节->线索”映射，供之后章节写作时快速查询某章需要写入哪些线索。
•	阶段校验：校验线索布置是否周全且合理：(a) 每条关键线索是否都分配到了至少一个章节，没有遗漏（通过比对线索列表和布置表确保覆盖）；(b) 每章是否避免无关线索（不引入未在真相规划中的多余线索，以免制造未解之谜）；(c) 线索呈现顺序是否由浅入深、符合悬疑节奏。此检查可借助程序或LLM：例如编程比对章节-线索映射覆盖了所有线索节点；或者提示LLM：“根据案件真相，检查上述线索布置是否会让真相在结尾揭示时水到渠成，是否有章节给出的线索过早暴露真相？” 模型反馈可辅助调整。经人工和模型确认一切妥当后，进入正式写作阶段。
阶段五：章节内容生成（逐章创作故事正文）
•	阶段目标：按照大纲和线索布置，逐章生成小说正文内容。确保文风统一（贴合福尔摩斯式严谨推理风格），剧情生动连贯，每章结尾制造悬念吸引读者阅读下一章。逐章生成有助于控制每部分字数和节奏，并利用前文记忆保持一致性[3]。
•	输入：主要输入包括当前章节的规划信息（该章在大纲中的描述、本章需要呈现的线索列表），以及已经写完的前文内容（用于保持上下文连续性）。此外，全局信息如故事背景、角色设定也持续有效，但这些可从先前阶段的结果中获取。
•	输出：每次生成当前章节的完整文字内容（几百至一千字左右，依实际需要调节），逐章叠加形成最终小说。每章文本应符合其大纲描述并恰当嵌入该章线索。生成过程中要监控字数使总篇幅接近5000字目标。
•	提示词设计：采用分阶段提示策略：对于每一章，都向LLM提供一个综合提示，内容包含： (1) 创作指令（小说总体要求和风格提醒，如“请继续撰写侦探小说第X章，风格上要求推理严谨、叙事流畅”）；(2) 章节大纲（本章主要剧情要点）；(3) 本章应包含的线索（列出需要写到的线索或伏笔细节）；(4) 已写内容摘要（上一章或前文剧情摘要，用于上下文连贯）。模型据此创作新章节[4]。例如Prompt模板：
[系统角色]: 你是一位优秀的小说写作助手，擅长推理故事写作。请根据提供的内容继续创作下文。
[用户角色]: 
小说背景与风格设定：{(摘要的全局设定，例如主角和故事基调)}
当前章节计划：{第X章的大纲内容}
本章需包含的线索：{列出线索及其要点}
已写内容摘要：{上文简要摘要或上一章结尾段落}
请根据上述信息，写出侦探小说的第X章正文，字数约{N}字。要求情节衔接自然，突出相关线索，保持悬念和推理风格。
通过这种提示，模型能整合已有内容和新要求去生成下一章文本[5]。注意在提示中反复强调风格和逻辑，以确保输出保持推理小说特有的语气和节奏。
•	实现方式：章节生成需要对每章重复上述提示-回复过程，可以使用循环调用LLMChain或借助LangChain的SequentialChain/RouterChain等组合多个步骤。如果采用LangGraph，可以将“写作节点”设计为接受当前章节信息和累积内容，然后输出新章节文本[6][7]。实际上，一个简单实现在Python中用for循环遍历章节列表，每次调用llm_chain.run(当前章节prompt)即可[8][9]。关键在于上下文管理：需将前文摘要或部分内容提供给模型[3]。可以采取以下策略保持记忆和一致性：
•	窗口记忆：直接在每次提示中附上已经完成的最近若干内容（比如上一章全文或概要）。这种方法直观，在上下文长度允许范围内有效[10]。如使用8K上下文的模型，5000字的全文几乎可一直带上下文，但为了稳妥可以只带最近1-2章内容和必要人物信息。
•	摘要记忆：当前文变长时，用另一LLMChain将已完成部分动态总结，提供给当前章节作为摘要上下文。这减少提示长度，同时保留情节关键点。
•	向量数据库检索：将前面章节或关键剧情嵌入向量存储（如FAISS），在撰写新章节前根据需要检索相关段落[2]。例如，如果第5章需要呼应第1章埋下的伏笔，可通过向量相似搜索找到第1章包含该线索的句子供模型参考。这种RAG（检索增强生成）方式能提高长篇内容的一致性[2]。LangChain提供VectorStoreRetrieverMemory等辅助类，将向量检索结果直接拼入模型上下文。
•	知识图谱查询：如果之前构建了故事知识图谱，此时也可用LangChain的图数据库查询功能。在生成章节时，让Agent调用Neo4j图查询以获取关于相关角色/线索的属性，确保模型不会偏离设定。例如，当写到某嫌疑人出场章节时，查询图谱获取其人际关系或作案时间线，以避免冲突。GraphRAG的思想是在生成时利用知识图提供结构化参考，提升准确性和细节可信度[11]。
•	记忆管理：正如上述，上下文记忆对长篇连贯很重要。本阶段可综合运用短期记忆（prompt上下文窗口）和长期记忆（摘要或向量检索）[2]。LangChain的Memory模块（如ConversationBufferMemory）可以存储对话历史，但在逐章生成中更直接的方法是手动维护text_so_far字符串，在每次迭代时更新。考虑性能，也可在每写完一章后将重要信息（比如新线索揭示情况、人物新动态）存入一个全局“状态”对象或知识库，供后续提取。关键是避免模型忘记前面发生的事或改变已有设定。
•	阶段校验：每生成完一章，先不要立即进入下一章，可进行以下检查：
•	长度控制：检查该章字数是否大致符合预期范围，必要时提示模型扩写或缩减。在LangChain链中可加入一个函数工具计算字数并反馈[12][13]。
•	内容校验：确保章节内容涵盖了该章应有的线索和情节。比如可用LLMChain提问：“本章是否提及了线索X？是否保持了悬念？” 如果缺漏，可以在下一轮提示中补充要求重写或增补细节。甚至可以用一个简单正则/关键词程序检查章节文本是否包含预期的线索关键词。
•	风格校验：人工快速阅读或用LLM总结本章，看是否符合推理风格和角色行为合理。例如若发现语气不对或逻辑不严谨，可调整提示词或在下一章引导修正。每章末尾如果需要制造悬念，可检查最后一段是否有引人继续的悬疑点，没有的话可让模型追加一句扣人心弦的结尾。
•	知识图一致性：如果使用图数据库，可在每章生成后将章节内容提取关键信息更新图谱，然后验证图中角色状态与案件真相一致。例如，如果某章揭示了嫌疑人的新线索，更新图谱该嫌疑人节点的信息，然后检查凶手的边是否保持隐蔽关系等。这可以通过LangChain调用Cypher查询实现自动化一致性检查。
通过上述循环“生成-校验-调整”，保证逐章创作符合规划，且最终所有章节串联成完整一稿。
阶段六：逻辑回收（整体校验与收尾润色）
•	阶段目标：在全文初稿完成后，对小说进行全局的逻辑和质量检查，回收之前埋下的所有伏笔，确保没有遗漏的线索或未解的问题，最终输出一个逻辑自恰、阅读流畅的故事成品。此阶段也包括对文字的润色和格式调整，使小说可读性更强。
•	输入：完整的小说文本（所有章节内容串联），以及之前的真相方案、线索列表等参考资料。
•	输出：定稿的小说文本。如有问题修正，还输出修改说明或标记。理想情况下，输出就是最终小说成品。
•	提示词设计：可以将此阶段分成两个子步骤：(1) 逻辑检查 – 提示LLM充当“推理小说审稿人”，阅读全文并回答一些检查问题；(2) 问题修正 – 如果发现问题，再提示LLM进行修订。 示例：
•	逻辑检查提示： “你是一位严谨的推理小说审阅者。请阅读下面的全文，并检查：a)故事中所有线索是否都在结局得到了解释；b)情节中有无自相矛盾或未交代清楚之处；c)推理过程是否合乎逻辑。列出你发现的任何问题或遗漏。” 模型根据小说全文回答问题列表。
•	问题修正提示： 若模型/人工发现问题，如某线索未在结尾揭示用途，可以提示：“请根据以下反馈修改小说相应部分。反馈：‘线索Z没有在结局揭示作用。’ 请在保证风格一致的前提下增补相关情节，使线索Z有所交代。” 模型将输出修改后的片段或建议。然后开发者可以将修改合并入全文。
也可以让模型直接输出修订后的全文，但由于长度较长，可能需分段修订或者让模型专注修改局部，以免破坏已有良好内容。
•	实现方式：使用LangChain的链式调用实现上述过程：首先一个LLMChain执行逻辑检查，之后根据结果决定是否进入修正环节。LangChain的Agent也可用于这一流程：比如构造一个工具集，包括“list_issues”（输出问题列表）和“revise_text”（根据问题修改文本）两个工具，由Agent先调用list_issues，然后如果列表非空则调用revise_text逐一解决问题。不过直接链式控制更简单。知识图谱辅助：也可在此时利用知识图验证故事一致性。例如，把最终文本输入LangChain的KnowledgeGraphChain来抽取其中的人物与事件关系，跟之前阶段规划的图谱比对，找出差异。如果某关系在计划中有但文本中没体现，则提示补充[14]。这种方法可程序化地发现遗漏的伏笔或人物出场。
•	记忆管理：此阶段主要处理全文，LLM需要一次读入较长文本。可使用长上下文模型（如GPT-4 32k）或者采用分段检查策略。如果模型无法一次吃下全文，则按章节分段检查，再综合汇总。另外，可以借助向量数据库进行全文检查提问：比如对每个线索关键词嵌入搜索正文，看有没有对应解释段落。如果搜索不到，则标记为遗漏。LangChain提供方便的向量检索接口，可用短提示多次检索辅助人工检查。
•	阶段校验：经过逻辑检查和修订后，应该做到：所有主要线索在结局都有解释，所有人物行为和时间线前后一致，读者不会感到困惑。这时可以做最终验收：再次用LLMChain请模型给小说写个简短总结或评论，看其对故事理解是否正确。如果连模型总结都能正确指出谁是凶手、案件如何破解，说明故事逻辑清晰。最后在人类编辑层面，做一次全文阅读确认文字流畅度、错别字等。LangSmith追踪：在整个开发与测试过程中，可以将所有链路集成到LangSmith进行调用跟踪和调试[15]。LangSmith提供了完善的链路追踪和调优界面，有助于发现哪个阶段提示不理想或模型输出异常[15]。开发者可利用这些日志不断优化提示词和链设计，提升系统稳定性。
额外考虑：交互界面与整体架构
在上述各阶段基础上，可以引入交互界面和监控工具以提升系统的易用性与可靠性：
•	多阶段链路编排： 推荐使用LangChain的LangGraph或SequentialChain来编排整个流程，将各阶段封装为节点顺序执行，实现模块化的流程控制[6][7]。例如，用LangGraph定义节点：ConceptNode -> TrickNode -> OutlineNode -> ClueNode -> WritingNode (loop) -> ReviewNode，使工作流清晰透明。每个节点内部是相应的LLMChain或自定义逻辑。这样的节点式架构方便在某一步出错时单独调试[6]。
•	用户交互（Streamlit/Gradio）： 可选用Streamlit或Gradio构建一个简单UI，让用户参与和监控创作过程。例如，用户在界面上提供初始要求，然后点击“生成故事大纲”，看到阶段一、二输出结果并可以微调角色设定或真相；然后点“生成章节”，系统按阶段顺序产出章节文本，用户可以一章章阅读并在必要时编辑提示或内容，然后继续下一章。这种人类监控-Human in the loop方式借助交互界面实现，可提高最终故事质量和个性化。Gradio/Streamlit可以轻松集成LangChain链的调用，将每阶段输出实时展示，按钮触发下一阶段，从而实现半自动化创作流程。
•	监控与迭代： 在开发调试过程中，充分利用LangSmith或LangChain内置调试日志来记录每次LLM调用的提示和响应[15]。这对于找出模型错误、调整提示格式很有帮助。另外，系统应设计为可以从中途重来：比如如果最后发现逻辑漏洞，需要回到阶段四重新分配线索，再从阶段五继续生成。良好的模块化让每阶段输出可保存和复用，从而避免全部重跑，提高效率。
经过以上多阶段工作流，最终将产出一部完成度高、可读性强、节奏合理、逻辑自洽的侦探短篇小说。分阶段创作为创意和逻辑把关提供了机制：从总体策划到细节布置，每一步都有明确输入输出和检查平衡，这正是LangChain架构所擅长的。“蛋蛋”这个11岁小侦探将在严密设计的情节中逐步破解谜团，给读者带来风格地道的本格推理体验。整个流程既发挥了大模型的创意和语言优势，又通过链式逻辑和外部存储确保了内容的一致性和可控性。通过LangChain强大的链式调用、记忆管理以及外部工具集成，我们能够成功地逐步生成这篇精彩的侦探小说，实现用户最初的创作目标。[3][1]
________________________________________
[1] [2] [11] [14] Guiding Generative Storytelling with Knowledge Graphs
https://arxiv.org/html/2505.24803v2
[3] [4] [5] [6] [7] [8] [9] [10] [12] [13] LLM——基于LangChain与LangGraph实现的长篇文章自动写作工作流_longchain+longgraph-CSDN博客
https://blog.csdn.net/weixin_43844521/article/details/149866058
[15] How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding
https://blog.langchain.com/customers-webtoon/
